{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network\n",
    "\n",
    "Source: https://github.com/haradai1262/CIKM2020-AnalytiCup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO\n",
    "- faire le dnn avec pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sns as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from verstack.stratified_continuous_split import scsplit  # pip install verstack\n",
    "\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "train_data=train_data.drop(['mentions'], axis=1)\n",
    "\n",
    "# Load the evaluation data\n",
    "eval_data = pd.read_csv(\"data/evaluation.csv\")\n",
    "eval_data=eval_data.drop(['mentions'], axis=1)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = scsplit(train_data, train_data['retweets_count'], stratify=train_data['retweets_count'], train_size=0.8, test_size=0.2)\n",
    "# We remove the actual number of retweets from our features since it is the value that we are trying to predict\n",
    "X_train = X_train.drop(['retweets_count'], axis=1)\n",
    "X_test = X_test.drop(['retweets_count'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrac features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def extract_time_features(df):\n",
    "    rs_df = df\n",
    "    rs_df[\"hour\"] = rs_df['timestamp'].apply(\n",
    "        lambda t: (datetime.fromtimestamp(t//1000).hour))\n",
    "    rs_df[\"day\"] = rs_df['timestamp'].apply(\n",
    "        lambda t: (datetime.fromtimestamp(t//1000)).weekday())\n",
    "    rs_df[\"week_in_month\"] = rs_df['timestamp'].apply(\n",
    "        lambda t: (datetime.fromtimestamp(t//1000).day)//7)  \n",
    "    rs_df=rs_df.drop(['timestamp'], axis=1)\n",
    "    return rs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_ratio_features(df):\n",
    "    rs_df = df\n",
    "    rs_df['followers__favorites'] = rs_df['followers_count'] * rs_df['favorites_count']\n",
    "    rs_df['friends__favorites'] = rs_df['friends_count'] * rs_df['favorites_count']\n",
    "    rs_df['followers__friends__favorites'] = rs_df['followers_count'] * rs_df['friends_count'] * rs_df['favorites_count']\n",
    "    return rs_df\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import zscore\n",
    "def extract_transfo(df,columns):\n",
    "    rs_df = df\n",
    "    for col in columns:\n",
    "        mean = rs_df[col].mean()\n",
    "        std = rs_df[col].std()\n",
    "        rs_df[col+'_cdf'] = norm.cdf(rs_df[col].values, loc=mean, scale=std)\n",
    "        rs_df[col+'_z'] = zscore(rs_df[col].values)       \n",
    "        rs_df[col+'_rank'] = rs_df[col].rank(method='min')\n",
    "        rs_df[col+'log'] = (df[col] + 1).apply(np.log)\n",
    "    return rs_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "def extract_topic(df):\n",
    "    rs_df = df\n",
    "    rs_df['hashtags'] = rs_df['hashtags'].apply(\n",
    "        lambda x: x.replace('[', '').replace(']', '').replace(\"'\", ''))\n",
    "    #join text and hashtags\n",
    "    rs_df['total_text'] = rs_df['text'] + ' ' + rs_df['hashtags']\n",
    "    vectorizer = TfidfVectorizer(min_df=1, max_features=None, stop_words=stopwords.words('french'))\n",
    "    vector = vectorizer.fit_transform(rs_df['text'])\n",
    "    svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "    svd.fit(vector)\n",
    "    topic=svd.transform(vector)\n",
    "    rs_df['topic_1'] = topic[:,0]\n",
    "    rs_df['topic_2'] = topic[:,1]\n",
    "    rs_df['topic_3'] = topic[:,2]\n",
    "    rs_df['topic_4'] = topic[:,3]\n",
    "    rs_df['topic_5'] = topic[:,4]\n",
    "    rs_df=rs_df.drop(['hashtags'],axis=1)\n",
    "    rs_df=rs_df.drop(['total_text'],axis=1)\n",
    "    return rs_df\n",
    "\n",
    "from textblob import TextBlob  # pip install textblob-fr\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "\n",
    "\n",
    "def sent_engineering(in_df):\n",
    "    rs_df = in_df\n",
    "    # add columns related to sentiment analysis\n",
    "    rs_df['polarity'] = rs_df['text'].apply(lambda x: TextBlob(\n",
    "        x, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer()).sentiment[0])\n",
    "    rs_df['subjectivity'] = rs_df['text'].apply(lambda x: TextBlob(\n",
    "        x, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer()).sentiment[1])\n",
    "    # drop the text column\n",
    "    rs_df = rs_df.drop(['text'], axis=1)\n",
    "    return rs_df\n",
    "\n",
    "def extract_url(in_df):\n",
    "    #count url\n",
    "    rs_df = in_df\n",
    "    rs_df['url_count'] = rs_df['urls'].apply(lambda x: len(x.split(',')))\n",
    "    rs_df=rs_df.drop(['urls'],axis=1)\n",
    "\n",
    "    return rs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "def extract_cluster(df,columns):\n",
    "    rs_df = df\n",
    "    rs_df['cluster'] = KMeans(n_clusters=100, random_state=0).fit_predict(rs_df[columns].values)\n",
    "    return rs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_metrics_features = [\n",
    "    'followers_count', 'friends_count', 'favorites_count',\n",
    "    'followers__favorites', 'friends__favorites', 'followers__friends__favorites',\n",
    "]\n",
    "\n",
    "tweet_metrics_log_features = [feat+'_log' for feat in tweet_metrics_features]\n",
    "tweet_metrics_cdf_features = [feat+'_cdf' for feat in tweet_metrics_features]\n",
    "tweet_metrics_z_features = [feat+'_z' for feat in tweet_metrics_features]\n",
    "tweet_metrics_rank_features = [feat+'_rank' for feat in tweet_metrics_features]\n",
    "\n",
    "time_cat_features = ['hour', 'day', 'week_of_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "new_X_train=extract_time_features(X_train)\n",
    "new_X_train=extract_ratio_features(new_X_train)\n",
    "new_X_train=extract_transfo(new_X_train,tweet_metrics_features)\n",
    "new_X_train=extract_topic(new_X_train)\n",
    "new_X_train=sent_engineering(new_X_train)\n",
    "new_X_train=extract_url(new_X_train)\n",
    "new_X_train=extract_cluster(new_X_train,['followers_count', 'friends_count', 'favorites_count','verified','statuses_count'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        favorites_count  followers_count  statuses_count  friends_count  \\\n",
      "145711                0              528           32283            236   \n",
      "174690                1              454             216            559   \n",
      "163477                0               29            1133            315   \n",
      "202410                0              679           28413            759   \n",
      "219776                0              412              73            608   \n",
      "\n",
      "        verified  TweetID  hour  day  week_in_month  followers__favorites  \\\n",
      "145711         0   698089    22    3              1                     0   \n",
      "174690         0   167320    17    5              1                   454   \n",
      "163477         0   221247    13    5              1                     0   \n",
      "202410         0   607469    20    3              1                     0   \n",
      "219776         0   264674    16    5              1                     0   \n",
      "\n",
      "        ...  followers__friends__favorites_rank  \\\n",
      "145711  ...                                 1.0   \n",
      "174690  ...                            215174.0   \n",
      "163477  ...                                 1.0   \n",
      "202410  ...                                 1.0   \n",
      "219776  ...                                 1.0   \n",
      "\n",
      "        followers__friends__favoriteslog   topic_1   topic_2   topic_3  \\\n",
      "145711                          0.000000  0.041918  0.000953 -0.008486   \n",
      "174690                         12.444251  0.006753  0.000437 -0.000285   \n",
      "163477                          0.000000  0.043943  0.007684 -0.010770   \n",
      "202410                          0.000000  0.013253  0.000301 -0.001605   \n",
      "219776                          0.000000  0.033506  0.006062  0.002907   \n",
      "\n",
      "         topic_4   topic_5  polarity  subjectivity  url_count  \n",
      "145711  0.029178  0.015679      0.01         0.000          1  \n",
      "174690  0.002233  0.002118      0.00         0.000          1  \n",
      "163477  0.005555  0.008647      0.00         0.000          1  \n",
      "202410  0.002718  0.006114     -0.70         0.700          1  \n",
      "219776 -0.000352  0.033682      0.06         0.075          1  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(new_X_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test=extract_time_features(X_test)\n",
    "new_X_test=extract_ratio_features(new_X_test)\n",
    "new_X_test=extract_transfo(new_X_test,tweet_metrics_features)\n",
    "new_X_test=extract_topic(new_X_test)\n",
    "new_X_test=sent_engineering(new_X_test)\n",
    "new_X_test=extract_url(new_X_test)\n",
    "new_X_test=extract_cluster(new_X_test,['followers_count', 'friends_count', 'favorites_count','verified','statuses_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mlp\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "remove=['TweetID']\n",
    "model=MLPRegressor(hidden_layer_sizes=(2048,512,128),activation='relu',\n",
    "                    solver='adam',alpha=0.001,batch_size='auto')\n",
    "model.fit(new_X_train.drop(remove, axis=1),y_train)\n",
    "y_pred = model.predict(new_X_test.drop(remove, axis=1))\n",
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buid an MLP with pytoch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(44, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = self.dropout3(out)\n",
    "\n",
    "        out = self.fc4(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "#convert to tensor\n",
    "X_train_tensor=torch.tensor(new_X_train.drop(remove, axis=1).values)\n",
    "X_test_tensor=torch.tensor(new_X_test.drop(remove, axis=1).values)\n",
    "y_train_tensor=torch.tensor(y_train.values)\n",
    "y_test_tensor=torch.tensor(y_test.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model class and assign to object\n",
    "model_dropout= DNN()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.RMSprop(model_dropout.parameters(), lr=1e-3)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "(train_acc, val_acc, train_loss, val_loss) = train_model(model_dropout, optimizer, criterion)\n",
    "\n",
    "def plot_losses(history_train_loss, history_val_loss):\n",
    "    # Set plotting style\n",
    "    #plt.style.use(('dark_background', 'bmh'))\n",
    "    plt.style.use('bmh')\n",
    "    plt.rc('axes', facecolor='none')\n",
    "    plt.rc('figure', figsize=(16, 4))\n",
    "\n",
    "    # Plotting loss graph\n",
    "    plt.plot(history_train_loss, label='Train')\n",
    "    plt.plot(history_val_loss, label='Validation')\n",
    "    plt.title('Loss Graph')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_losses(train_loss, val_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca02d05c83cb06a4d3d1bb3c2ad95bd9ee4b26f688526444572dc942a69d580d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
