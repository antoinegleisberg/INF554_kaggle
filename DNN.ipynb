{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sns as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from verstack.stratified_continuous_split import scsplit  # pip install verstack\n",
    "\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "train_data=train_data.drop(['mentions'], axis=1)\n",
    "\n",
    "# Load the evaluation data\n",
    "eval_data = pd.read_csv(\"data/evaluation.csv\")\n",
    "eval_data=eval_data.drop(['mentions'], axis=1)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = scsplit(train_data, train_data['retweets_count'], stratify=train_data['retweets_count'], train_size=0.8, test_size=0.2)\n",
    "# We remove the actual number of retweets from our features since it is the value that we are trying to predict\n",
    "X_train = X_train.drop(['retweets_count'], axis=1)\n",
    "X_test = X_test.drop(['retweets_count'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def extract_time_features(df):\n",
    "    rs_df = df\n",
    "    rs_df[\"hour\"] = rs_df['timestamp'].apply(\n",
    "        lambda t: (datetime.fromtimestamp(t//1000).hour))\n",
    "    rs_df[\"day\"] = rs_df['timestamp'].apply(\n",
    "        lambda t: (datetime.fromtimestamp(t//1000)).weekday())\n",
    "    rs_df[\"week_in_month\"] = rs_df['timestamp'].apply(\n",
    "        lambda t: (datetime.fromtimestamp(t//1000).day)//7)  \n",
    "    rs_df=rs_df.drop(['timestamp'], axis=1)\n",
    "    return rs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_ratio_features(df):\n",
    "    rs_df = df\n",
    "    rs_df['followers__favorites'] = rs_df['followers_count'] * rs_df['favorites_count']\n",
    "    rs_df['friends__favorites'] = rs_df['friends_count'] * rs_df['favorites_count']\n",
    "    rs_df['followers__friends__favorites'] = rs_df['followers_count'] * rs_df['friends_count'] * rs_df['favorites_count']\n",
    "    return rs_df\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import zscore\n",
    "def extract_transfo(df,columns):\n",
    "    rs_df = df\n",
    "    for col in columns:\n",
    "        mean = rs_df[col].mean()\n",
    "        std = rs_df[col].std()\n",
    "        rs_df[col+'_cdf'] = norm.cdf(rs_df[col].values, loc=mean, scale=std)\n",
    "        rs_df[col+'_z'] = zscore(rs_df[col].values)       \n",
    "        rs_df[col+'_rank'] = rs_df[col].rank(method='min')\n",
    "        rs_df[col+'_log'] = (df[col] + 1).apply(np.log)\n",
    "    return rs_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "def extract_topic(df):\n",
    "    rs_df = df\n",
    "    rs_df['hashtags'] = rs_df['hashtags'].apply(\n",
    "        lambda x: x.replace('[', '').replace(']', '').replace(\"'\", ''))\n",
    "    #join text and hashtags\n",
    "    rs_df['total_text'] = rs_df['text'] + ' ' + rs_df['hashtags']\n",
    "    vectorizer = TfidfVectorizer(min_df=1, max_features=None, stop_words=stopwords.words('french'))\n",
    "    vector = vectorizer.fit_transform(rs_df['text'])\n",
    "    svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "    svd.fit(vector)\n",
    "    topic=svd.transform(vector)\n",
    "    rs_df['topic_1'] = topic[:,0]\n",
    "    rs_df['topic_2'] = topic[:,1]\n",
    "    rs_df['topic_3'] = topic[:,2]\n",
    "    rs_df['topic_4'] = topic[:,3]\n",
    "    rs_df['topic_5'] = topic[:,4]\n",
    "    rs_df=rs_df.drop(['hashtags'],axis=1)\n",
    "    rs_df=rs_df.drop(['total_text'],axis=1)\n",
    "    return rs_df\n",
    "\n",
    "from textblob import TextBlob  # pip install textblob-fr\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "\n",
    "\n",
    "def sent_engineering(in_df):\n",
    "    rs_df = in_df\n",
    "    # add columns related to sentiment analysis\n",
    "    rs_df['polarity'] = rs_df['text'].apply(lambda x: TextBlob(\n",
    "        x, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer()).sentiment[0])\n",
    "    rs_df['subjectivity'] = rs_df['text'].apply(lambda x: TextBlob(\n",
    "        x, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer()).sentiment[1])\n",
    "    # drop the text column\n",
    "    rs_df = rs_df.drop(['text'], axis=1)\n",
    "    return rs_df\n",
    "\n",
    "def extract_url(in_df):\n",
    "    #count url\n",
    "    rs_df = in_df\n",
    "    rs_df['url_count'] = rs_df['urls'].apply(lambda x: len(x.split(',')))\n",
    "    rs_df=rs_df.drop(['urls'],axis=1)\n",
    "\n",
    "    return rs_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "def extract_cluster(df,columns):\n",
    "    rs_df = df\n",
    "    rs_df['cluster'] = KMeans(n_clusters=100, random_state=0).fit_predict(rs_df[columns].values)\n",
    "    return rs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our categories of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_metrics_features = [\n",
    "    'followers_count', 'friends_count', 'favorites_count',\n",
    "    'followers__favorites', 'friends__favorites', 'followers__friends__favorites',\n",
    "]\n",
    "\n",
    "tweet_metrics_log_features = [feat+'_log' for feat in tweet_metrics_features]\n",
    "tweet_metrics_cdf_features = [feat+'_cdf' for feat in tweet_metrics_features]\n",
    "tweet_metrics_z_features = [feat+'_z' for feat in tweet_metrics_features]\n",
    "tweet_metrics_rank_features = [feat+'_rank' for feat in tweet_metrics_features]\n",
    "time_cat_features = ['hour', 'day', 'week_of_month']\n",
    "text_features = ['subjectivity', 'polarity', 'topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5']\n",
    "other_features = ['url_count', 'cluster']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "new_X_train=extract_time_features(X_train)\n",
    "new_X_train=extract_ratio_features(new_X_train)\n",
    "new_X_train=extract_transfo(new_X_train,tweet_metrics_features)\n",
    "new_X_train=extract_topic(new_X_train)\n",
    "new_X_train=sent_engineering(new_X_train)\n",
    "new_X_train=extract_url(new_X_train)\n",
    "new_X_train=extract_cluster(new_X_train,['followers_count', 'friends_count', 'favorites_count','statuses_count'])\n",
    "\n",
    "\n",
    "\n",
    "col=new_X_train.columns\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test=extract_time_features(X_test)\n",
    "new_X_test=extract_ratio_features(new_X_test)\n",
    "new_X_test=extract_transfo(new_X_test,tweet_metrics_features)\n",
    "new_X_test=extract_topic(new_X_test)\n",
    "new_X_test=sent_engineering(new_X_test)\n",
    "new_X_test=extract_url(new_X_test)\n",
    "new_X_test=extract_cluster(new_X_test,['followers_count', 'friends_count', 'favorites_count','statuses_count'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "   favorites_count  followers_count  statuses_count  friends_count  verified  \\\n",
      "0        -0.055427        -0.077747       -0.414041      -0.559132 -0.175892   \n",
      "\n",
      "    TweetID      hour       day  week_in_month  followers__favorites  ...  \\\n",
      "0  1.518406 -0.707831  1.035836       0.736276             -0.018636  ...   \n",
      "\n",
      "   followers__friends__favorites_log   topic_1  topic_2   topic_3   topic_4  \\\n",
      "0                          -0.598136 -0.296151  -0.0715  0.296761 -0.339997   \n",
      "\n",
      "   topic_5  polarity  subjectivity  url_count   cluster  \n",
      "0  2.19863  0.686551      0.317495  -0.071037 -0.317596  \n",
      "\n",
      "[1 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler #standard scaler seems to perform better\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(new_X_train)\n",
    "new_X_train_s = scaler.transform(new_X_train)\n",
    "new_X_test_s = scaler.transform(new_X_test)\n",
    "\n",
    "print(type(new_X_train_s))\n",
    "#array to pd\n",
    "new_X_train_s=pd.DataFrame(new_X_train_s, columns=col)\n",
    "new_X_test_s=pd.DataFrame(new_X_test_s, columns=col)\n",
    "#rindex columns\n",
    "new_X_train_s=new_X_train_s.reindex(columns=col)\n",
    "new_X_test_s=new_X_test_s.reindex(columns=col)\n",
    "print(new_X_train_s.head(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping useless columns: ['TweetID', 'followers_count_rank', 'friends_count_rank', 'favorites_count_rank', 'followers__favorites_rank', 'friends__favorites_rank', 'followers__friends__favorites_rank', 'followers_count_z', 'friends_count_z', 'favorites_count_z', 'followers__favorites_z', 'friends__favorites_z', 'followers__friends__favorites_z', 'followers_count_cdf', 'friends_count_cdf', 'favorites_count_cdf', 'followers__favorites_cdf', 'friends__favorites_cdf', 'followers__friends__favorites_cdf', 'followers_count_log', 'friends_count_log', 'favorites_count_log', 'followers__favorites_log', 'friends__favorites_log', 'followers__friends__favorites_log']\n",
      "Training model...\n",
      "Epoch 1/8\n",
      "8850/8850 [==============================] - 120s 14ms/step - loss: 8.5069 - mae: 8.3252\n",
      "Epoch 2/8\n",
      "8850/8850 [==============================] - 134s 15ms/step - loss: 7.9563 - mae: 7.6956\n",
      "Epoch 3/8\n",
      "8850/8850 [==============================] - 124s 14ms/step - loss: 7.7997 - mae: 7.5109\n",
      "Epoch 4/8\n",
      "8850/8850 [==============================] - 134s 15ms/step - loss: 7.7244 - mae: 7.4207\n",
      "Epoch 5/8\n",
      "8850/8850 [==============================] - 131s 15ms/step - loss: 7.7190 - mae: 7.4165\n",
      "Epoch 6/8\n",
      "8850/8850 [==============================] - 121s 14ms/step - loss: 7.8192 - mae: 7.5121\n",
      "Epoch 7/8\n",
      "8850/8850 [==============================] - 123s 14ms/step - loss: 7.6187 - mae: 7.3061\n",
      "Epoch 8/8\n",
      "8850/8850 [==============================] - 127s 14ms/step - loss: 7.6775 - mae: 7.3611\n"
     ]
    }
   ],
   "source": [
    "#import sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_dnn_model(input):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2048, input_dim=input.shape[1], activation='relu', kernel_regularizer=regularizers.L2(l2=0.0001)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.L2(l2=0.0001)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.L2(l2=0.0001)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='relu', kernel_regularizer=regularizers.L2(l2=0.0001)))\n",
    "\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "remove=['TweetID']+tweet_metrics_rank_features+tweet_metrics_z_features+tweet_metrics_cdf_features+tweet_metrics_log_features\n",
    "\n",
    "print('dropping useless columns:', remove)\n",
    "\n",
    "print('Training model...')\n",
    "model = build_dnn_model(\n",
    "    new_X_train_s.drop(remove, axis=1))\n",
    "history = model.fit(\n",
    "    new_X_train_s.drop(remove,axis=1), y_train, epochs=12,  verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.235647015027092\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(new_X_test_s.drop(remove, axis=1))\n",
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca02d05c83cb06a4d3d1bb3c2ad95bd9ee4b26f688526444572dc942a69d580d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
