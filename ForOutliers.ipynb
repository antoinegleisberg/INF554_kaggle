{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF554 Kaggle challenge notebook\n",
    "Team: Kagglers\n",
    "\n",
    "Members: Marian Huot, Antoine Gleisberg, Aude Bouillé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from verstack.stratified_continuous_split import scsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Load the evaluation data\n",
    "eval_data = pd.read_csv(\"data/evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.252581440747637\n"
     ]
    }
   ],
   "source": [
    "# Average word count per tweet\n",
    "print(np.mean(np.array([train_data[\"text\"][i].count(' ') for i in range(len(train_data[\"text\"]))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers with retweets_count above n\n",
    "def remove_outliers_above(df, col, n):\n",
    "    df = df[df[col] < n]\n",
    "    return df\n",
    "\n",
    "def percentage_outliers_above(df, col, n):\n",
    "    z = df[col].copy()\n",
    "    z[z < n] = 0\n",
    "    print(f\"n = {n} ; Percentage of outliers : {round(len(z[z > 0]) / len(z) * 100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 7000 ; Percentage of outliers : 0.0155%\n"
     ]
    }
   ],
   "source": [
    "percentage_outliers_above(train_data, 'retweets_count', 7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['TweetID', 'mention', 'urls', 'timestamp', 'text', 'total_text', 'hashtags', 'followers_count', 'friends_count', 'favorites_count', 'statuses_count', 'verified', 'url_count', 'followers_friends',\n",
    "       'hour', 'day','week_in_month', 'polarity', 'subjectivity', 'hashtags_count', 'topic_1','topic_2', 'topic_3','topic_4', 'topic_5','cluster']\n",
    "\n",
    "useless_cols = [\"TweetID\", \"mention\", \"urls\", \"timestamp\", \"text\", \"hashtags\", \"total_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines: List[Tuple[str, bool, Tuple[float, float], Pipeline]] = []\n",
    "#pipelines.append(('ScaledKNN',      False, (0, 0), Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor(5))])))\n",
    "#pipelines.append(('ScaledRF',       False, (0, 0), Pipeline([('Scaler', StandardScaler()),('RF', RandomForestRegressor(n_estimators=10))])))\n",
    "pipelines.append(('UnscaledRF',     False, (0, 0), Pipeline([('RF', RandomForestRegressor(n_estimators=10))])))\n",
    "\n",
    "\n",
    "# pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n",
    "# pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\n",
    "# pipelines.append(('OptimizedRF', Pipeline([('RF', RandomForestRegressor(max_features=0.93, max_leaf_nodes=2310, n_estimators=90, n_jobs=-1))])))\n",
    "# pipelines.append(('OptimizedXGB', Pipeline([('XGB', XGBRegressor(base_score=0.5, booster='gbtree'))])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions_to_file(file_name, eval_data, predictions):\n",
    "    with open(file_name, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"TweetID\", \"retweets_count\"])\n",
    "        for index, prediction in enumerate(predictions):\n",
    "            writer.writerow([str(eval_data['TweetID'].iloc[index]) , str(round(prediction))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "UnscaledRF: -5.397619111800038 (0.289856156052332)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 7.250388450998672\n",
      "5250\n",
      "UnscaledRF: -5.448423444323973 (0.20496298208550745)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 7.205667146933356\n",
      "5500\n",
      "UnscaledRF: -5.452374286232218 (0.19912195600958824)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 7.65833262705879\n",
      "5750\n",
      "UnscaledRF: -5.490453121872535 (0.29667372970190997)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.855552730457384\n",
      "6000\n",
      "UnscaledRF: -5.513578370659965 (0.3098757356424935)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 7.238551289657315\n",
      "6250\n",
      "UnscaledRF: -5.6651571927386986 (0.3486339339558479)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.779091448427833\n",
      "6500\n",
      "UnscaledRF: -5.636866110371128 (0.2969508885341222)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.636960759386389\n",
      "6750\n",
      "UnscaledRF: -5.7675200746096 (0.2033255064152532)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 7.389143147724384\n",
      "7000\n",
      "UnscaledRF: -5.7184167262609344 (0.17708091470790482)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 7.031556346583044\n",
      "7250\n",
      "UnscaledRF: -5.803783702124602 (0.42056845262876075)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.732138316806509\n",
      "7500\n",
      "UnscaledRF: -5.827816174086125 (0.4009256530399997)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.900556544339916\n",
      "7750\n",
      "UnscaledRF: -5.777666667273329 (0.3242835595099051)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 7.1360849789530185\n",
      "8000\n",
      "UnscaledRF: -5.9961866794291225 (0.2870194877498937)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.84656891826991\n",
      "8250\n",
      "UnscaledRF: -6.0036469400297925 (0.359911572597961)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.89468034014182\n",
      "8500\n",
      "UnscaledRF: -5.993208859687341 (0.2666622237075625)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.950560781987174\n",
      "8750\n",
      "UnscaledRF: -6.045329019546459 (0.37466794818602595)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.49824843913326\n",
      "9000\n",
      "UnscaledRF: -6.0359102598466565 (0.41671869903898096)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.8137695284911155\n",
      "9250\n",
      "UnscaledRF: -5.968808040382038 (0.2719186893768838)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.54496143740995\n",
      "9500\n",
      "UnscaledRF: -6.04767550590025 (0.37415321890343517)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.819391473853717\n",
      "9750\n",
      "UnscaledRF: -6.1820427335334625 (0.3859783876656396)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.661878125264853\n",
      "10000\n",
      "UnscaledRF: -6.01128750100476 (0.48581275488766285)\n",
      "UnscaledRF done.\n",
      "Mean absolute error: 6.807610814475803\n"
     ]
    }
   ],
   "source": [
    "for n in range(5000, 10001, 250):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    # split data using stratified continuous split\n",
    "    X_train, X_test, y_train, y_test = scsplit(train_data, train_data['retweets_count'], stratify=train_data['retweets_count'], train_size=0.8, test_size=0.2)\n",
    "\n",
    "    X_train['retweets_count'] = y_train\n",
    "    # remove outliers according to visualization\n",
    "    X_train = remove_outliers_above(X_train, 'retweets_count', n)\n",
    "    # split again\n",
    "    y_train = X_train['retweets_count']\n",
    "    #X_train = X_train.drop('retweets_count',axis=1)\n",
    "\n",
    "    # We remove the actual number of retweets from our features since it is the value that we are trying to predict\n",
    "    X_train = X_train.drop(['retweets_count'], axis=1)\n",
    "    X_test = X_test.drop(['retweets_count'], axis=1)\n",
    "    \n",
    "    ids = X_test[\"TweetID\"]\n",
    "    \n",
    "    new_train_data = clean_data(X_train, columns, useless_cols)\n",
    "    new_test_data = clean_data(X_test, columns, useless_cols)\n",
    "    \n",
    "    pipelines: List[Tuple[str, bool, Tuple[float, float], Pipeline]] = []\n",
    "    #pipelines.append(('ScaledKNN',      False, (0, 0), Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor(5))])))\n",
    "    #pipelines.append(('ScaledRF',       False, (0, 0), Pipeline([('Scaler', StandardScaler()),('RF', RandomForestRegressor(n_estimators=10))])))\n",
    "    pipelines.append(('UnscaledRF',     False, (0, 0), Pipeline([('RF', RandomForestRegressor(n_estimators=10))])))\n",
    "\n",
    "    for i, (name, was_evaluated, (mean, std), model) in enumerate(pipelines):\n",
    "        if not was_evaluated:\n",
    "            kfold = KFold(n_splits=10)\n",
    "            cv_results = cross_val_score(model, new_train_data, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "            pipelines[i] = (name, True, (cv_results.mean(), cv_results.std()), model)\n",
    "        print(f\"{name}: {pipelines[i][2][0]} ({pipelines[i][2][1]})\")\n",
    "\n",
    "    #La cross validation nous donne deja les perfs de chaque modèle\n",
    "    for name, was_evaluated, (mean, std), model in pipelines:\n",
    "        model.fit(new_train_data, y_train)\n",
    "        predictions = model.predict(new_test_data)\n",
    "        predictions = [round(value) if value >= 0 else 0 for value in predictions]\n",
    "        print(f\"{name} done.\\nMean absolute error: {mean_absolute_error(y_test, predictions)}\")\n",
    "        y_test[\"TweetID\"] = ids\n",
    "        write_predictions_to_file(\"result\" + str(n) + name + \".csv\", y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''5000\n",
    "UnscaledRF: -5.397619111800038 (0.289856156052332)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 7.250388450998672\n",
    "5250\n",
    "UnscaledRF: -5.448423444323973 (0.20496298208550745)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 7.205667146933356\n",
    "5500\n",
    "UnscaledRF: -5.452374286232218 (0.19912195600958824)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 7.65833262705879\n",
    "5750\n",
    "UnscaledRF: -5.490453121872535 (0.29667372970190997)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.855552730457384\n",
    "6000\n",
    "UnscaledRF: -5.513578370659965 (0.3098757356424935)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 7.238551289657315\n",
    "6250\n",
    "UnscaledRF: -5.6651571927386986 (0.3486339339558479)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.779091448427833\n",
    "6500\n",
    "UnscaledRF: -5.636866110371128 (0.2969508885341222)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.636960759386389\n",
    "6750\n",
    "UnscaledRF: -5.7675200746096 (0.2033255064152532)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 7.389143147724384\n",
    "7000\n",
    "UnscaledRF: -5.7184167262609344 (0.17708091470790482)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 7.031556346583044\n",
    "7250\n",
    "UnscaledRF: -5.803783702124602 (0.42056845262876075)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.732138316806509\n",
    "7500\n",
    "UnscaledRF: -5.827816174086125 (0.4009256530399997)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.900556544339916\n",
    "7750\n",
    "UnscaledRF: -5.777666667273329 (0.3242835595099051)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 7.1360849789530185\n",
    "8000\n",
    "UnscaledRF: -5.9961866794291225 (0.2870194877498937)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.84656891826991\n",
    "8250\n",
    "UnscaledRF: -6.0036469400297925 (0.359911572597961)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.89468034014182\n",
    "8500\n",
    "UnscaledRF: -5.993208859687341 (0.2666622237075625)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.950560781987174\n",
    "8750\n",
    "UnscaledRF: -6.045329019546459 (0.37466794818602595)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.49824843913326\n",
    "9000\n",
    "UnscaledRF: -6.0359102598466565 (0.41671869903898096)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.8137695284911155\n",
    "9250\n",
    "UnscaledRF: -5.968808040382038 (0.2719186893768838)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.54496143740995\n",
    "9500\n",
    "UnscaledRF: -6.04767550590025 (0.37415321890343517)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.819391473853717\n",
    "9750\n",
    "UnscaledRF: -6.1820427335334625 (0.3859783876656396)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.661878125264853\n",
    "10000\n",
    "UnscaledRF: -6.01128750100476 (0.48581275488766285)\n",
    "UnscaledRF done.\n",
    "Mean absolute error: 6.807610814475803'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "ScaledKNN: -7.894287009114071 (0.3450909842333503)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.339463796366923\n",
      "5250\n",
      "ScaledKNN: -7.9791470557487205 (0.37644014608130455)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.563818967709128\n",
      "5500\n",
      "ScaledKNN: -8.093326449306732 (0.4496690576257772)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.815280956013222\n",
      "5750\n",
      "ScaledKNN: -8.168020601944681 (0.3120656475183672)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.49057829759584\n",
      "6000\n",
      "ScaledKNN: -8.276324046103232 (0.2635531132901475)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.443879424810012\n",
      "6250\n",
      "ScaledKNN: -8.416929714360524 (0.21574769657913068)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 10.159420289855072\n",
      "6500\n",
      "ScaledKNN: -8.341485117416562 (0.32338256711440094)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.458386303924062\n",
      "6750\n",
      "ScaledKNN: -8.609397567799274 (0.3272407252791545)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.865878464276634\n",
      "7000\n",
      "ScaledKNN: -8.557966683274076 (0.26358452519277437)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.459855354973586\n",
      "7250\n",
      "ScaledKNN: -8.706649846273757 (0.3092808655535725)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.723620645817443\n",
      "7500\n",
      "ScaledKNN: -8.821736749583033 (0.3255753348757769)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.57663078791988\n",
      "7750\n",
      "ScaledKNN: -8.84258876252095 (0.38725615045695283)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.54897307681442\n",
      "8000\n",
      "ScaledKNN: -8.939930837164232 (0.38227086718514885)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.743269203604825\n",
      "8250\n",
      "ScaledKNN: -8.972601649639518 (0.3455014977246472)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.739977964234257\n",
      "8500\n",
      "ScaledKNN: -8.89523998035651 (0.322745322638089)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 10.12790631974461\n",
      "8750\n",
      "ScaledKNN: -9.04791708050973 (0.46818573663030916)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.359281860044636\n",
      "9000\n",
      "ScaledKNN: -9.069125251195596 (0.32251208583782914)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.814814814814815\n",
      "9250\n",
      "ScaledKNN: -9.1081402632278 (0.4154507979759329)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.573212419131565\n",
      "9500\n",
      "ScaledKNN: -9.06810171990799 (0.48794427008242136)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 10.597875526174535\n",
      "9750\n",
      "ScaledKNN: -9.196238742715874 (0.47392663619712594)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 9.770489024493601\n",
      "10000\n",
      "ScaledKNN: -9.130936877339785 (0.5337880460690733)\n",
      "ScaledKNN done.\n",
      "Mean absolute error: 10.022346526541797\n"
     ]
    }
   ],
   "source": [
    "for n in range(5000, 10001, 250):\n",
    "\n",
    "    print(n)\n",
    "\n",
    "    # split data using stratified continuous split\n",
    "    X_train, X_test, y_train, y_test = scsplit(train_data, train_data['retweets_count'], stratify=train_data['retweets_count'], train_size=0.8, test_size=0.2)\n",
    "\n",
    "    X_train['retweets_count'] = y_train\n",
    "    # remove outliers according to visualization\n",
    "    X_train = remove_outliers_above(X_train, 'retweets_count', n)\n",
    "    # split again\n",
    "    y_train = X_train['retweets_count']\n",
    "    #X_train = X_train.drop('retweets_count',axis=1)\n",
    "\n",
    "    # We remove the actual number of retweets from our features since it is the value that we are trying to predict\n",
    "    X_train = X_train.drop(['retweets_count'], axis=1)\n",
    "    X_test = X_test.drop(['retweets_count'], axis=1)\n",
    "    \n",
    "    ids = X_test[\"TweetID\"]\n",
    "    \n",
    "    new_train_data = clean_data(X_train, columns, useless_cols)\n",
    "    new_test_data = clean_data(X_test, columns, useless_cols)\n",
    "    \n",
    "    pipelines: List[Tuple[str, bool, Tuple[float, float], Pipeline]] = []\n",
    "    pipelines.append(('ScaledKNN',      False, (0, 0), Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor(5))])))\n",
    "    #pipelines.append(('ScaledRF',       False, (0, 0), Pipeline([('Scaler', StandardScaler()),('RF', RandomForestRegressor(n_estimators=10))])))\n",
    "    #pipelines.append(('UnscaledRF',     False, (0, 0), Pipeline([('RF', RandomForestRegressor(n_estimators=10))])))\n",
    "\n",
    "    for i, (name, was_evaluated, (mean, std), model) in enumerate(pipelines):\n",
    "        if not was_evaluated:\n",
    "            kfold = KFold(n_splits=10)\n",
    "            cv_results = cross_val_score(model, new_train_data, y_train, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "            pipelines[i] = (name, True, (cv_results.mean(), cv_results.std()), model)\n",
    "        print(f\"{name}: {pipelines[i][2][0]} ({pipelines[i][2][1]})\")\n",
    "\n",
    "    #La cross validation nous donne deja les perfs de chaque modèle\n",
    "    for name, was_evaluated, (mean, std), model in pipelines:\n",
    "        model.fit(new_train_data, y_train)\n",
    "        predictions = model.predict(new_test_data)\n",
    "        predictions = [round(value) if value >= 0 else 0 for value in predictions]\n",
    "        print(f\"{name} done.\\nMean absolute error: {mean_absolute_error(y_test, predictions)}\")\n",
    "        y_test[\"TweetID\"] = ids\n",
    "        write_predictions_to_file(\"result\" + str(n) + name + \".csv\", y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5000\n",
    "ScaledKNN: -7.894287009114071 (0.3450909842333503)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.339463796366923\n",
    "5250\n",
    "ScaledKNN: -7.9791470557487205 (0.37644014608130455)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.563818967709128\n",
    "5500\n",
    "ScaledKNN: -8.093326449306732 (0.4496690576257772)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.815280956013222\n",
    "5750\n",
    "ScaledKNN: -8.168020601944681 (0.3120656475183672)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.49057829759584\n",
    "6000\n",
    "ScaledKNN: -8.276324046103232 (0.2635531132901475)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.443879424810012\n",
    "6250\n",
    "ScaledKNN: -8.416929714360524 (0.21574769657913068)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 10.159420289855072\n",
    "6500\n",
    "ScaledKNN: -8.341485117416562 (0.32338256711440094)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.458386303924062\n",
    "6750\n",
    "ScaledKNN: -8.609397567799274 (0.3272407252791545)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.865878464276634\n",
    "7000\n",
    "ScaledKNN: -8.557966683274076 (0.26358452519277437)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.459855354973586\n",
    "7250\n",
    "ScaledKNN: -8.706649846273757 (0.3092808655535725)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.723620645817443\n",
    "7500\n",
    "ScaledKNN: -8.821736749583033 (0.3255753348757769)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.57663078791988\n",
    "7750\n",
    "ScaledKNN: -8.84258876252095 (0.38725615045695283)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.54897307681442\n",
    "8000\n",
    "ScaledKNN: -8.939930837164232 (0.38227086718514885)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.743269203604825\n",
    "8250\n",
    "ScaledKNN: -8.972601649639518 (0.3455014977246472)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.739977964234257\n",
    "8500\n",
    "ScaledKNN: -8.89523998035651 (0.322745322638089)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 10.12790631974461\n",
    "8750\n",
    "ScaledKNN: -9.04791708050973 (0.46818573663030916)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.359281860044636\n",
    "9000\n",
    "ScaledKNN: -9.069125251195596 (0.32251208583782914)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.814814814814815\n",
    "9250\n",
    "ScaledKNN: -9.1081402632278 (0.4154507979759329)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.573212419131565\n",
    "9500\n",
    "ScaledKNN: -9.06810171990799 (0.48794427008242136)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 10.597875526174535\n",
    "9750\n",
    "ScaledKNN: -9.196238742715874 (0.47392663619712594)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 9.770489024493601\n",
    "10000\n",
    "ScaledKNN: -9.130936877339785 (0.5337880460690733)\n",
    "ScaledKNN done.\n",
    "Mean absolute error: 10.022346526541797'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5906c532cfa2adbf56dd818a659b28cf8a28c7bd18a371f873e9dccaa083b26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
